---
layout: about
title: about
permalink: /
subtitle: 김<b>원재</b> · ML/HCI Research Scientist

profile:
  align: right
  image: prof_pic5.jpg
  image_circular: false # crops the image to make it circular

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: true
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

I lead the Embedding & Search team at [TwelveLabs](https://www.twelvelabs.io), where we build multimodal foundation models for video understanding. I'm the first author of [ViLT](https://github.com/dandelin/ViLT) <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user={{ site.data.socials.scholar_userid }}&citation_for_view={{ site.data.socials.scholar_userid }}:YsMSGLbcyi4C" style="font-size: 0.85em; color: var(--global-text-color-light);">(cited: {{ site.data.citations.papers['UpZ41EwAAAAJ:YsMSGLbcyi4C'].citations }})</a>, one of the early works that shaped efficient vision-language architectures. Previously, I was a research scientist at [Naver AI LAB](https://naver-career.gitbook.io/en/teams/clova-cic) and [Kakao](https://www.kakaocorp.com/?lang=en), and I hold an [M.Sc.](http://hcil.snu.ac.kr/people/wonjae-kim) and [B.Sc.](https://cse.snu.ac.kr/en) from Seoul National University.

My current research focuses on:

- Multimodal Representation Learning (video, audio, text)
- Large-scale Embedding & Search Systems
- User Behavior Modeling for Search

---

**We're Hiring!** I'm building a research team at TwelveLabs where your models ship to thousands of customers within months. We're tackling joint embedding spaces across modalities and containerized asset search—problems that go beyond simple retrieval to true semantic understanding of video structure. If you want to see your work create real-world impact at scale, [grab a coffee chat](https://calendar.app.google/RFWg71Zb3GED9nkeA) with me. I'm looking for scientists and engineers who are excited to push video-language AI from idea to production. [Join us in Seoul →](https://jobs.ashbyhq.com/twelve-labs/38e8e1c9-bf91-449c-b64a-c3f481099801)
